{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a2b184",
   "metadata": {},
   "source": [
    "### Task: Neural Style Transfer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a91fffb",
   "metadata": {},
   "source": [
    "#### For this task, I have selected two datasets. First, the dataset of best artworks of all time, and other is the dataset of Images of Dragon Ball Z characters. I will choose a style image from the art dataset and train the CNN network to transfer its style to the anime characters' images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695ad572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awast\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc18b4",
   "metadata": {},
   "source": [
    "### Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd921719",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a23bcb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "\n",
    "        files = os.listdir(folder_path)\n",
    "        image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        self.images = [Image.open(os.path.join(folder_path, image_file)) for image_file in image_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "# Define a transformation to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "]) \n",
    "\n",
    "# Create a custom dataset\n",
    "dataset = ContentDataset(folder_path=\"C:\\\\Users\\\\awast\\\\Downloads\\\\archive_3\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404d5689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3145"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size=len(dataset)\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf905027",
   "metadata": {},
   "source": [
    "#### Importing Pretrained VGG network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855c7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8396bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1085a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we are going to select a few layers to calculate the content and style loss\n",
    "#layers_list=['0','5','10','19','28']\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG,self).__init__()\n",
    "        \n",
    "        self.model=models.vgg19(pretrained=True).features[:29]\n",
    "        self.layers_list=['0','5','10','19','28']\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features=[]\n",
    "        \n",
    "        for layer_numb,layer in enumerate(self.model):\n",
    "            x=layer(x)\n",
    "            if str(layer_numb) in self.layers_list:\n",
    "                features.append(x)\n",
    "        \n",
    "        return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e59535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  (Original Normalization constansts for the VGG network)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def plot_image(tensor):\n",
    "#     if not torch.jit.is_scripting() and not torch.jit.is_tracing():\n",
    "#         _log_api_usage_once(save_image)\n",
    "#     grid = make_grid(tensor, **kwargs)\n",
    "    # Add 0.5 after unnormalizing to [0, 255] to round to the nearest integer\n",
    "    ndarr = tensor.mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to(\"cpu\", torch.uint8).numpy()\n",
    "    im = Image.fromarray(ndarr)\n",
    "    plt.imshow(im)\n",
    "\n",
    "def load_image(image):\n",
    "    image = loader(image).unsqueeze(0)\n",
    "    return image.to(device)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# image_size = 224\n",
    "\n",
    "\n",
    "\n",
    "# original_img = dataset[0]\n",
    "# style_img = load_image(styles[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacb3213",
   "metadata": {},
   "source": [
    "#### I have used an encoder decoder architecture, which will take the original image as the input and output the stylized image as the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "335693a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EncodeDecoder(nn.Module):\n",
    "   \n",
    "    def __init__(self):\n",
    "        super(EncodeDecoder, self).__init__()\n",
    "        self.ConvBlock = nn.Sequential(\n",
    "            ConvLayer(3, 32, 9, 1),\n",
    "            nn.ReLU(),\n",
    "            ConvLayer(32, 64, 3, 2),\n",
    "            nn.ReLU(),\n",
    "            ConvLayer(64, 128, 3, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.ResidualBlock = nn.Sequential(\n",
    "            ResidualLayer(128, 3), \n",
    "            ResidualLayer(128, 3), \n",
    "            ResidualLayer(128, 3), \n",
    "            ResidualLayer(128, 3), \n",
    "            ResidualLayer(128, 3)\n",
    "        )\n",
    "        self.DeconvBlock = nn.Sequential(\n",
    "            DeconvLayer(128, 64, 3, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            DeconvLayer(64, 32, 3, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            ConvLayer(32, 3, 9, 1, norm=\"None\")\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ConvBlock(x)\n",
    "        x = self.ResidualBlock(x)\n",
    "        out = self.DeconvBlock(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, norm=\"instance\"):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        # Padding Layers\n",
    "        padding_size = kernel_size // 2\n",
    "        self.reflection_pad = nn.ReflectionPad2d(padding_size)\n",
    "\n",
    "        # Convolution Layer\n",
    "        self.conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "        # Normalization Layers\n",
    "        self.norm_type = norm\n",
    "        if (norm==\"instance\"):\n",
    "            self.norm_layer = nn.InstanceNorm2d(out_channels, affine=True)\n",
    "        elif (norm==\"batch\"):\n",
    "            self.norm_layer = nn.BatchNorm2d(out_channels, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reflection_pad(x)\n",
    "        x = self.conv_layer(x)\n",
    "        if (self.norm_type==\"None\"):\n",
    "            out = x\n",
    "        else:\n",
    "            out = self.norm_layer(x)\n",
    "        return out\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels=128, kernel_size=3):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.conv1 = ConvLayer(channels, channels, kernel_size, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = ConvLayer(channels, channels, kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x                     # preserve residual\n",
    "        out = self.relu(self.conv1(x))   # 1st conv layer + activation\n",
    "        out = self.conv2(out)            # 2nd conv layer\n",
    "        out = out + identity             # add residual\n",
    "        return out\n",
    "\n",
    "class DeconvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, output_padding, norm=\"instance\"):\n",
    "        super(DeconvLayer, self).__init__()\n",
    "\n",
    "        # Transposed Convolution \n",
    "        padding_size = kernel_size // 2\n",
    "        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding_size, output_padding)\n",
    "\n",
    "        # Normalization Layers\n",
    "        self.norm_type = norm\n",
    "        if (norm==\"instance\"):\n",
    "            self.norm_layer = nn.InstanceNorm2d(out_channels, affine=True)\n",
    "        elif (norm==\"batch\"):\n",
    "            self.norm_layer = nn.BatchNorm2d(out_channels, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_transpose(x)\n",
    "        if (self.norm_type==\"None\"):\n",
    "            out = x\n",
    "        else:\n",
    "            out = self.norm_layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5f32884",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, vgg_path=\"vgg16-00b39a1b.pth\"):\n",
    "        super(VGG16, self).__init__()\n",
    "        # Load VGG Skeleton, Pretrained Weights\n",
    "        vgg16_features = models.vgg16(pretrained=False)\n",
    "        vgg16_features.load_state_dict(torch.load(vgg_path), strict=False)\n",
    "        self.features = vgg16_features.features\n",
    "\n",
    "        # Turn-off Gradient History\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        layers = {'3': 'relu1_2', '8': 'relu2_2', '15': 'relu3_3', '22': 'relu4_3'}\n",
    "        features = {}\n",
    "        for name, layer in self.features._modules.items():\n",
    "            x = layer(x)\n",
    "            if name in layers:\n",
    "                features[layers[name]] = x\n",
    "                if (name=='22'):\n",
    "                    break\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad932f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41d798",
   "metadata": {},
   "source": [
    "#### Calculating Gram Matrix to quantify style loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd8f86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gram Matrix\n",
    "def gram(tensor):\n",
    "    B, C, H, W = tensor.shape\n",
    "    x = tensor.view(B, C, H*W)\n",
    "    x_t = x.transpose(1, 2)\n",
    "    return  torch.bmm(x, x_t) / (C*H*W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e94a4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show image\n",
    "def show(img):\n",
    "    # Convert from BGR to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # imshow() only accepts float [0,1] or int [0,255]\n",
    "    img = np.array(img/255).clip(0,1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def saveimg(img, image_path):\n",
    "    img = img.clip(0, 255)\n",
    "    cv2.imwrite(image_path, img)\n",
    "\n",
    "# Preprocessing ~ Image to Tensor\n",
    "def itot(img, max_size=None):\n",
    "    # Rescale the image\n",
    "    if (max_size==None):\n",
    "        itot_t = transforms.Compose([\n",
    "            #transforms.ToPILImage(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.mul(255))\n",
    "        ])    \n",
    "    else:\n",
    "        H, W, C = img.shape\n",
    "        image_size = tuple([int((float(max_size) / max([H,W]))*x) for x in [H, W]])\n",
    "        itot_t = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.mul(255))\n",
    "        ])\n",
    "\n",
    "    # Convert image to tensor\n",
    "    tensor = itot_t(img)\n",
    "\n",
    "    # Add the batch_size dimension\n",
    "    tensor = tensor.unsqueeze(dim=0)\n",
    "    return tensor\n",
    "\n",
    "# Preprocessing ~ Tensor to Image\n",
    "def ttoi(tensor):\n",
    "    \n",
    "    tensor = tensor.squeeze()\n",
    "    #img = ttoi_t(tensor)\n",
    "    img = tensor.cpu().numpy()\n",
    "    \n",
    "    # Transpose from [C, H, W] -> [H, W, C]\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8998f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(styles[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c96eb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "TRAIN_IMAGE_SIZE = 224\n",
    "DATASET_PATH = \"C:\\\\Users\\\\awast\\\\Downloads\\\\dragon_ball\"\n",
    "NUM_EPOCHS = 5\n",
    "# STYLE_IMAGE_PATH = \"images/mosaic.jpg\"\n",
    "style_datapath=\"C:\\\\Users\\\\awast\\\\Downloads\\\\artworks\"\n",
    "files = os.listdir(style_datapath)\n",
    "image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "styles = [Image.open(os.path.join(style_datapath, image_file)) for image_file in image_files]\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4 \n",
    "CONTENT_WEIGHT = 10\n",
    "STYLE_WEIGHT = 1\n",
    "ADAM_LR = 0.001\n",
    "SAVE_MODEL_PATH = \"C:/Users/awast/dashtoon/models/\"\n",
    "SAVE_IMAGE_PATH = \"C:/Users/awast/dashtoon/images/out/\"\n",
    "SAVE_MODEL_EVERY = 100 # 2,000 Images with batch size 4\n",
    "SEED = 35\n",
    "PLOT_LOSS = 1\n",
    "\n",
    "def train():\n",
    "    # Seeds\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    # Device\n",
    "    device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Dataset and Dataloader\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(TRAIN_IMAGE_SIZE),\n",
    "        transforms.CenterCrop(TRAIN_IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Lambda(lambda x: x.mul(255))\n",
    "    ])\n",
    "    train_dataset = datasets.ImageFolder(DATASET_PATH, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # Load networks\n",
    "    TransformerNetwork1 = EncodeDecoder().to(device)\n",
    "    VGG = VGG16().to(device)\n",
    "\n",
    "    imagenet_neg_mean = torch.tensor([-103.939, -116.779, -123.68], dtype=torch.float32).reshape(1,3,1,1).to(device)\n",
    "    style_image = styles[4]\n",
    "    style_tensor = itot(style_image).to(device)\n",
    "    style_tensor = style_tensor.add(imagenet_neg_mean)\n",
    "    B, C, H, W = style_tensor.shape\n",
    "    style_features = VGG(style_tensor.expand([BATCH_SIZE, C, H, W]))\n",
    "    style_gram = {}\n",
    "    for key, value in style_features.items():\n",
    "        style_gram[key] = gram(value)\n",
    "\n",
    "    # Optimizer settings\n",
    "    optimizer = optim.Adam(TransformerNetwork1.parameters(), lr=ADAM_LR)\n",
    "\n",
    "    # Loss trackers\n",
    "    content_loss_history = []\n",
    "    style_loss_history = []\n",
    "    total_loss_history = []\n",
    "    batch_content_loss_sum = 0\n",
    "    batch_style_loss_sum = 0\n",
    "    batch_total_loss_sum = 0\n",
    "\n",
    "    # Optimization/Training Loop\n",
    "    batch_count = 1\n",
    "    start_time = time.time()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(\"========Epoch {}/{}========\".format(epoch+1, NUM_EPOCHS))\n",
    "        for content_batch, _ in train_loader:\n",
    "            # Get current batch size in case of odd batch sizes\n",
    "            curr_batch_size = content_batch.shape[0]\n",
    "\n",
    "            # Free-up unneeded cuda memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Zero-out Gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Generate images and get features\n",
    "            content_batch = content_batch[:,[2,1,0]].to(device)\n",
    "            generated_batch = TransformerNetwork1(content_batch)\n",
    "            content_features = VGG(content_batch.add(imagenet_neg_mean))\n",
    "            generated_features = VGG(generated_batch.add(imagenet_neg_mean))\n",
    "\n",
    "            # Content Loss\n",
    "            MSELoss = nn.MSELoss().to(device)\n",
    "            content_loss = CONTENT_WEIGHT * MSELoss(generated_features['relu2_2'], content_features['relu2_2'])            \n",
    "            batch_content_loss_sum += content_loss\n",
    "\n",
    "            # Style Loss\n",
    "            style_loss = 0\n",
    "            for key, value in generated_features.items():\n",
    "                s_loss = MSELoss(gram(value), style_gram[key][:curr_batch_size])\n",
    "                style_loss += s_loss\n",
    "            style_loss *= STYLE_WEIGHT\n",
    "            batch_style_loss_sum += style_loss.item()\n",
    "\n",
    "            # Total Loss\n",
    "            total_loss = content_loss + style_loss\n",
    "            print(style_loss)\n",
    "            batch_total_loss_sum += total_loss.item()\n",
    "\n",
    "            # Backprop and Weight Update\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save Model and Print Losses\n",
    "            if (((batch_count-1)%SAVE_MODEL_EVERY == 0) or (batch_count==NUM_EPOCHS*len(train_loader))):\n",
    "                # Print Losses\n",
    "                print(\"========Iteration {}/{}========\".format(batch_count, NUM_EPOCHS*len(train_loader)))\n",
    "                print(\"\\tContent Loss:\\t{:.2f}\".format(batch_content_loss_sum/batch_count))\n",
    "                print(\"\\tStyle Loss:\\t{:.2f}\".format(batch_style_loss_sum/batch_count))\n",
    "                print(\"\\tTotal Loss:\\t{:.2f}\".format(batch_total_loss_sum/batch_count))\n",
    "                print(\"Time elapsed:\\t{} seconds\".format(time.time()-start_time))\n",
    "\n",
    "                # Save Model\n",
    "                checkpoint_path = SAVE_MODEL_PATH + \"checkpoint_\" + str(batch_count-1) + \".pth\"\n",
    "                torch.save(TransformerNetwork1.state_dict(), checkpoint_path)\n",
    "                print(\"Saved TransformerNetwork checkpoint file at {}\".format(checkpoint_path))\n",
    "\n",
    "                # Save sample generated image\n",
    "                sample_tensor = generated_batch[0].clone().detach().unsqueeze(dim=0)\n",
    "                sample_image = sample_tensor.clone().detach().squeeze().cpu().numpy().transpose(1,2,0)\n",
    "                sample_image_path = SAVE_IMAGE_PATH + \"sample0_\" + str(batch_count-1) + \".png\"\n",
    "#                 np.save(sample_image, sample_image_path)\n",
    "#                 utils.saveimg(sample_image, sample_image_path)\n",
    "                sample_image = sample_image.clip(0, 255)\n",
    "                cv2.imwrite(sample_image_path, sample_image)\n",
    "                print(\"Saved sample tranformed image at {}\".format(sample_image_path))\n",
    "\n",
    "                # Save loss histories\n",
    "                content_loss_history.append(batch_total_loss_sum/batch_count)\n",
    "                style_loss_history.append(batch_style_loss_sum/batch_count)\n",
    "                total_loss_history.append(batch_total_loss_sum/batch_count)\n",
    "\n",
    "            # Iterate Batch Counter\n",
    "            batch_count+=1\n",
    "\n",
    "\n",
    "    # Save TransformerNetwork weights\n",
    "    TransformerNetwork1.eval()\n",
    "    TransformerNetwork1.cpu()\n",
    "    final_path = SAVE_MODEL_PATH + \"transformer_weight.pth\"\n",
    "    print(\"Saving TransformerNetwork weights at {}\".format(final_path))\n",
    "    torch.save(TransformerNetwork1.state_dict(), final_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24292f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awast\\anaconda3\\envs\\nlp\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\awast\\anaconda3\\envs\\nlp\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Epoch 1/5========\n",
      "tensor(3084150.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "========Iteration 1/6610========\n",
      "\tContent Loss:\t628.96\n",
      "\tStyle Loss:\t3084150.25\n",
      "\tTotal Loss:\t3084779.25\n",
      "Time elapsed:\t0.6199982166290283 seconds\n",
      "Saved TransformerNetwork checkpoint file at C:/Users/awast/dashtoon/models/checkpoint_0.pth\n",
      "Saved sample tranformed image at C:/Users/awast/dashtoon/images/out/sample0_0.png\n",
      "tensor(3050835., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3012108.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2969441.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2926210.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2890251.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2844592., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2800557., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2731735.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2700549.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2687741., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2681563., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2621547.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2562201., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2565454.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2539171., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2527629.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2487518., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2454152.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2409186.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2441770.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2444045., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2392816., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2375254.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2350381.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2335499.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2303548.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2328704., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2330507.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2329200.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2310092.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2296307., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2314607.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2297758.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2307476., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2275802., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2274840.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2272847.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2275012., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2292045.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2266490.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2218297., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2234881.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2246229.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2245221., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2250336., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2237957.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2230403., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2217854., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2207432.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2189562.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2201478., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2213957.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2191277.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2174198.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2171292.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2185878., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2187210.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2209117.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2183623., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2160450.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2183899., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2138936.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2145245., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2148423., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2131979.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2137079., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2150172.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2134660.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2148334.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2150846., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2138229.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2121134.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2109686.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2130487.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2114108.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2086813.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2118435.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2135929.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2122148.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2113162.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2077653., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2093262.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2073373.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2064559.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2098700.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2072547.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2070999.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2103138., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2095520.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2072814.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2107136.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2072066.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2058270., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2072218.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2085169.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2092300.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2070920.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2063743.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2046461.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2064567.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "========Iteration 101/6610========\n",
      "\tContent Loss:\t258276.91\n",
      "\tStyle Loss:\t2294390.08\n",
      "\tTotal Loss:\t2552667.08\n",
      "Time elapsed:\t21.77999758720398 seconds\n",
      "Saved TransformerNetwork checkpoint file at C:/Users/awast/dashtoon/models/checkpoint_100.pth\n",
      "Saved sample tranformed image at C:/Users/awast/dashtoon/images/out/sample0_100.png\n",
      "tensor(2041373.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2039672.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2032715.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2046502.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2059370.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2065867., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2005764.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2018006.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2031276.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2037253.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2060034.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2050475., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2055977.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2045484.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2065863.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2036346.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2038486., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2050632., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2024017.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1998120.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2001829.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2031144.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2015927.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1986644.3750, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1987772.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2018502.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2025779.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1986368.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2007494., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1965761.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1971101.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1951400.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1980376.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2012253., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1986196.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1959255.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1991935.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1983224.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1981140.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1996721.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1967741.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1977054.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1968751.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1970318.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1981994., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1946350.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1969957.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1976917.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1958732.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1967316.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1938357.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1924602.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1933849.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1927467.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1949845., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1915130.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1936436.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1939705.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1978471.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1941250.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1923884.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1904414.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1899660.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1917294., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1909000.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1943681.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1918904.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1925960.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1925555.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1928615.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1939395.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1917747.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1912142.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1909010.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1930292.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1953912.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1886303.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1930790.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1969895.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1900591.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1870436.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1879491.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1886019.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1908097.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1931272.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1904340.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1894483.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1888479., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1872296., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1884483.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1886443.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1870390.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1811374., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1852112.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1898284.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1910562., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1881531.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1900071., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1918299.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1889211.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "========Iteration 201/6610========\n",
      "\tContent Loss:\t341950.03\n",
      "\tStyle Loss:\t2127524.63\n",
      "\tTotal Loss:\t2469474.73\n",
      "Time elapsed:\t46.24099802970886 seconds\n",
      "Saved TransformerNetwork checkpoint file at C:/Users/awast/dashtoon/models/checkpoint_200.pth\n",
      "Saved sample tranformed image at C:/Users/awast/dashtoon/images/out/sample0_200.png\n",
      "tensor(1849931.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1850288.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1866326.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1873760.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1878480.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1880256.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1858941.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1838601.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1829724.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1838619.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1871144.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1833963.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1832899., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1817748.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1873454.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1818335.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1842552., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1816449., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1830738., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1834688.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1797304.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1814765.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1809004.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1799894.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1834201.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1863333.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1830154.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1811145.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1808420.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1783072.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1813824.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1803974.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1799573.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1836871.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1803169.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1808015.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1827847., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1786427.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1787595.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1794440.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1782504.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1767417.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1768679.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1754103.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1784556.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1757310.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1776840., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1792742.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1747581., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1768111.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1765193.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1758615., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1735460.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1753178.5000, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1791236.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1708350.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1743488.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1769300.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1748281.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1741592.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1777139.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1739145.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1727909.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1735427.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1762792., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1740666.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1706101.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1718616.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1714055.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1730870.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1739284.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1741815., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1707560.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1714825.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1688283.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1726886., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1720226.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1712863.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1721991.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1708073., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1705542.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1681782.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1713844.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1698448., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1688786.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1685123.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1678380., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1702262.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1706214.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1699134.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1703714.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1686358.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1690299.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1712950.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1696782.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1715582.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1683694.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1631988.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1686880.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1717007.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "========Iteration 301/6610========\n",
      "\tContent Loss:\t411717.03\n",
      "\tStyle Loss:\t2008027.41\n",
      "\tTotal Loss:\t2419744.44\n",
      "Time elapsed:\t71.0289978981018 seconds\n",
      "Saved TransformerNetwork checkpoint file at C:/Users/awast/dashtoon/models/checkpoint_300.pth\n",
      "Saved sample tranformed image at C:/Users/awast/dashtoon/images/out/sample0_300.png\n",
      "tensor(1718303.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1719172.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1686766.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1662360., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1629122., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1656506.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1678060.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1667284., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1681900.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1671965.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1686656.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1661194.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1694839.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1691683.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1650653.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1654903.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1663885.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1674941.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1676228.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1699145.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1652314.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1658199., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1643865.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1675241., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1681080.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1659764.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1656296.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1681234., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1667063.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1675656.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1662404.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1649291.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1648528.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1664559.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1660079.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1654593.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1644498., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1655890., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1634217., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1647269.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1664834.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1661861.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1677764.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1648019.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1652963.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1649505.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1656050.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1631782., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1623177.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1643453.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1634941.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1646436.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1628987.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1649140., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1616731.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1640476.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1624449.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1652389.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1643949.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1646358.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1606273.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1610204.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1614439.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1606187.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1604642.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1629521.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1607766.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1651707.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1628534.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1607901.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1634843.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1600094.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1589168., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1609581.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1638210.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1664393.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1627039.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1634243.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1613730., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1601786.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1641290.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1620566.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1612951.5000, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1601839.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1592740.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1599640., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1622984.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1643923.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1636341.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1595251.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1617130.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1604843.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1639093.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1629182.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1600806.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1578248.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1607383.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1588572.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1596396.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1615704.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "========Iteration 401/6610========\n",
      "\tContent Loss:\t462868.00\n",
      "\tStyle Loss:\t1916788.79\n",
      "\tTotal Loss:\t2379656.79\n",
      "Time elapsed:\t94.25399398803711 seconds\n",
      "Saved TransformerNetwork checkpoint file at C:/Users/awast/dashtoon/models/checkpoint_400.pth\n",
      "Saved sample tranformed image at C:/Users/awast/dashtoon/images/out/sample0_400.png\n",
      "tensor(1613147.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1651122.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1599445., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1631970.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1595875.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1598819.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1592860.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1630110.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1598031., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1596660.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1617096., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1640573.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1612300.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1585787.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1576071.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1604166.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1612831.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1581271., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1598290.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1597483.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1614068.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1620552.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1589782.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1588565.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1615483., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1582181.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1621007.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1616964.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1645931.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1549998., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1583401.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1604059.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1555133.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1617146.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1615950.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1593471.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1622283., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1580500.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1610889.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1567257., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1571684.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1601948.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1574885.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1572782.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1626244.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1571533.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1557229.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1588668.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1587373.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1579743.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1635721.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1562470.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1601513.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1596852.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1557874.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1618042.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1571376., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1608910.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1578716.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1573990.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1556387.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1572128.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1566826.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1570182.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1605005.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1579516.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1646786.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1582338.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1583005.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1562497.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1620028.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1561295.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1574148.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1553947.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1584438.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1550569.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1545232.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1616320.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1566757.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1562107.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1551111.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1567134.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1574935.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1573240., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1617807.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1529367.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1553469., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1574300.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1570102.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1558640.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1577789., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1589499.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1529975.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1577577.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1552486.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1593087.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1583019.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1553989.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1559241.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1593216.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "========Iteration 501/6610========\n",
      "\tContent Loss:\t497181.69\n",
      "\tStyle Loss:\t1851173.48\n",
      "\tTotal Loss:\t2348355.04\n",
      "Time elapsed:\t116.40699338912964 seconds\n",
      "Saved TransformerNetwork checkpoint file at C:/Users/awast/dashtoon/models/checkpoint_500.pth\n",
      "Saved sample tranformed image at C:/Users/awast/dashtoon/images/out/sample0_500.png\n",
      "tensor(1561806., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1580378.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1569558.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1542096.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1550098.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1539583.8750, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1571141.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1574780.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1583520.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1562287.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1548270.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1558366.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1535390.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1579666.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1582967.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1550784., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1571886.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1571067., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1579177.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1567447.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1574515.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1562440.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1578631.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1539454.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1551149.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1544410., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1534054.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1563394.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1582066.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1582278.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1576082.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1514673.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1523525.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1543361.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1548466.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1585296.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1574175.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1537525.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1595560.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1584278.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1524456.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1554027.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1563975.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1575544.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1560573.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1558477.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1517406.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1572036., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1524001., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1522294.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1524080.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1561436.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1541257.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1592070.7500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1593104.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1585416.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1507940., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1531514.8750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1567831.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1548743.2500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1543048.1250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1543531.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1567356.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1534129., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1533367.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1530418.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1560683.7500, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2138321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(total_steps=10000,alpha=0.1,beta=0.01,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0765f740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff9b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49e80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
